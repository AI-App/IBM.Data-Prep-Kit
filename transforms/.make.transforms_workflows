include ${REPOROOT}/.make.versions
include ${REPOROOT}/kfp/requirements.env

# Include the common rules.
# Use "make help" to see them.
include ${REPOROOT}/.make.defaults

USE_DEV_IMAGES ?= 1

define set_env_var
	$(eval export $(1)=$(2))
endef

.PHONY: .transforms_workflows.reconcile-requirements
.transforms_workflows.reconcile-requirements:
	cd ${REPOROOT}/kfp/kfp_ray_components && $(MAKE) reconcile-requirements
	@while IFS= read -r line; do \
		[ -z "$$line" ] && continue; \
		[[ $$line == *#* ]] && continue; \
		export DOCKER_IMAGE_NAME=$$(echo $$line |cut -d "=" -f 1 |sed "s/_VERSION//" |tr '[:upper:]' '[:lower:]'); \
		export DOCKER_IMAGE_VERSION=$$(echo $$line |cut -d "=" -f 2); \
		sed -i.back "s/data-prep-kit\/$$DOCKER_IMAGE_NAME:.*/data-prep-kit\/$$DOCKER_IMAGE_NAME:$$DOCKER_IMAGE_VERSION\"/" $$PIPELINE_FILE ;\
	done < ${REPOROOT}/.make.versions
ifeq ($(KFPv2), 1)
	@sed -i.back "s/kfp-data-processing_v2:.*/kfp-data-processing_v2:${KFP_DOCKER_VERSION_v2}\"/" ${PIPELINE_FILE}
else
	@sed -i.back "s/kfp-data-processing:.*/kfp-data-processing:${KFP_DOCKER_VERSION}\"/" ${PIPELINE_FILE}
endif


.PHONY: .transforms_workflows.compile-pipeline
.transforms_workflows.compile-pipeline:
	. ${WORKFLOW_VENV_ACTIVATE} && ${PYTHON} ${WF_NAME}.py

FORCE:

%.yaml: %.py FORCE
	$(MAKE) .transforms_workflows.reconcile-requirements PIPELINE_FILE=$<
	$(MAKE) .transforms_workflows.compile-pipeline WF_NAME=$(shell (basename $< .py))

.PHONY: .transforms_workflows.test-pipeline
.transforms_workflows.test-pipeline:
	@# Help: upload and run the workflow. Set export USE_DEV_IMAGES=0 to use release docker image versions.
	$(call set_env_var, CLUSTER_EXISTS, $(shell kind get clusters | grep ${KIND_CLUSTER_NAME}))
	@if [ -z ${CLUSTER_EXISTS} ]; then \
		cd ${REPOROOT} && make setup;  \
	fi
ifeq ($(USE_DEV_IMAGES), 1)
	cd ${TRANSFORM_SRC} && $(MAKE) image && $(MAKE) load-image
	cd ${REPOROOT}/kfp/kfp_ray_components && $(MAKE) image && $(MAKE) load-image
endif
	. ${WORKFLOW_VENV_ACTIVATE}  && ${PYTHON} -m workflow_support.utils.pipelines_tests_utils -c "sanity-test" -p ${CURDIR}/${PIPELINE_FILE}

${WORKFLOW_VENV_ACTIVATE}: ${REPOROOT}/.make.versions ${REPOROOT}/kfp/requirements.env ${REPOROOT}/kfp/kfp_ray_components/requirements.txt ${DPK_RAY_LIB_DIR} ${REPOROOT}/kfp/kfp_support_lib/
	rm -rf ${REPOROOT}/transforms/venv
	$(MAKE) -C ${REPOROOT}/transforms .defaults.python-lib-src-venv
	. ${WORKFLOW_VENV_ACTIVATE};     \
	pip install -e $(REPOROOT)/kfp/kfp_support_lib/python_apiserver_client; \
    pip install -e $(DPK_PYTHON_LIB_DIR); \
	pip install -e $(DPK_RAY_LIB_DIR); \
	pip install kfp==$(KFP) --extra-index-url https://pypi.org/simple; \
	pip install -e $(REPOROOT)/kfp/kfp_support_lib/$(WORKFLOW_SUPPORT_LIB);
	@# Help: Create the virtual environment common to all workflows

.PHONY: .transforms_workflows.upload-pipeline
.transforms_workflows.upload-pipeline:
	$(call set_env_var, CLUSTER_EXISTS, $(shell kind get clusters | grep ${KIND_CLUSTER_NAME}))
	@if [ -z ${CLUSTER_EXISTS} ]; then \
		cd ${REPOROOT} && make setup;  \
	fi
	. ${WORKFLOW_VENV_ACTIVATE}  && ${PYTHON} -m workflow_support.utils.pipelines_tests_utils -c "upload" -p ${CURDIR}/${PIPELINE_FILE}

